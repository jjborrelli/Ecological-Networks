tind[which(round(tind$TL) == 1),]
length(tind[which(round(tind$TL) == 1),])
nrow(tind[which(round(tind$TL) == 1),])
177/1095
print(web.props)
names(tind[which(round(tind$TL) == 1),])
rownames(tind[which(round(tind$TL) == 1),])
library(taxize)
specieslist <- rownames(tind[which(round(tind$TL) == 1),])
classification(specieslist, db = "itis")
testclas<- classification(specieslist[1:5], db = "itis")
testclas
library(RCurl)
url <- getURL("https://raw.github.com/bw4sz/IntroR/master/05-DataExploration/Traits.csv")
traits <- read.csv(text = url)
traits
head(traits)
require(ggplot2)
traits <- read.csv(text = url, rownames = 1)
traits <- read.csv(text = url, row.names = 1)
head(traits)
require(ggplot2)
?table
table(traits$Genus~traits$Clade)
table(traits$Genus,traits$Clade)
?range
head(trait)
head(traits)
table(Clade, Genus, data = traits)
table(traits$Clade, traits$Genus)
head(traits)
which.max(traits$Bill)
traits[which.max(traits$Bill)]
traits[which.max(traits$Bill),]
traits[which.max(traits$Bill),]$Clade
traits$Genus[which.max(traits$Bill)]
traits[which.max(traits$Bill),]
qplot(tind$TL, binwidth = .25, geom = "histogram",
xlab = "Trophic Position", ylab = "Frequency")
source('~/.active-rstudio-document', echo=TRUE)
qplot(tind$TL, binwidth = .25, geom = "histogram",
xlab = "Trophic Position", ylab = "Frequency")
dd <- ggplot(data.frame(degrees = degrees), aes(x = degrees))
dd <- dd + geom_histogram(aes(y=..density..), binwidth = 5, colour = "black", fill = "white")
sequ <- seq(1, 300, .25)
dd <- dd + geom_line(aes(x = sequ[1:1095],
y = dlnorm(sequ[1:1095], degdisfit[[1]][1], degdisfit[[1]][2])),
colour = "blue")
dd <- dd + geom_line(aes(x = sequ[1:1095], y = 20 * sequ[1:1095] ^ -degdispow$alpha, colour = "green"))
dd + scale_y_continuous(limits = c(0, 0.12)) + theme(legend.position = "none")
degdisfit <- fitdistr(degrees, "lognormal")
degdispow <- power.law.fit(degrees, force.continuous = T)
dd <- ggplot(data.frame(degrees = degrees), aes(x = degrees))
dd <- dd + geom_histogram(aes(y=..density..), binwidth = 5, colour = "black", fill = "white")
sequ <- seq(1, 300, .25)
dd <- dd + geom_line(aes(x = sequ[1:1095],
y = dlnorm(sequ[1:1095], degdisfit[[1]][1], degdisfit[[1]][2])),
colour = "blue")
dd <- dd + geom_line(aes(x = sequ[1:1095], y = 20 * sequ[1:1095] ^ -degdispow$alpha, colour = "green"))
dd + scale_y_continuous(limits = c(0, 0.12)) + theme(legend.position = "none")
degdisfit
degrees
degrees <- degree(SOgraph, mode = "all")
degrees
degdisfit <- fitdistr(degrees, "lognormal")
degdispow <- power.law.fit(degrees, force.continuous = T)
dd <- ggplot(data.frame(degrees = degrees), aes(x = degrees))
dd <- dd + geom_histogram(aes(y=..density..), binwidth = 5, colour = "black", fill = "white")
dd
sequ <- seq(1, 300, .25)
dd <- dd + geom_line(aes(x = sequ[1:1095],
y = dlnorm(sequ[1:1095], degdisfit[[1]][1], degdisfit[[1]][2])),
colour = "blue")
dd <- dd + geom_line(aes(x = sequ[1:1095], y = 20 * sequ[1:1095] ^ -degdispow$alpha, colour = "green"))
dd + scale_y_continuous(limits = c(0, 0.12)) + theme(legend.position = "none")
ggplot(web.props1) + geom_point(aes(x = N, y = C))
ggplot(web.props1) + geom_point(aes(x = N, y = C)) + geom_smooth()
ggplot(web.props1, aes(x = N, y = C)) + geom_point() + geom_smooth()
?geom_smooth
nn[,1]
nn[,1:3]
ggplot(data = nn) + geom_bar(y = nn[1,])
ggplot(data = data.frame(nn)) + geom_bar(y = nn[1,])
ggplot(data = data.frame(nn)) + geom_bar(x = 1:228, y = nn[1,])
ggplot(data = data.frame(nn)) + geom_bar(aes(x = 1:228, y = nn[1,]))
data.frame(nn[,1:5])
ggplot(data = web.props) + geom_bar(aes(y = Bas))
ggplot(data = web.props) + geom_bar(aes(x = 1:228, y = Bas))
ggplot(data = web.props) + geom_bar(aes(x = 1:228, y = Bas)) +geom_bar(aes(x=1:228, y = Int))
pSO <- permatfull(SOadjacency, fixedmar = "row", mtype = "prab", times = 100)
?t.test
?prop.test
??wald
??score
?prop.test
prop.CI = function(p, n, alpha = 0.05, digits = 3, method = "likelihood") {
# Asymptotic (or Wald) interval:
z = qnorm(1 - alpha/2)
if (method == "asymptotic") {
se = sqrt(p * (1 - p)/n)
CI = list(p = p, CI = c((p - z * se), (p + z * se)), n = n, level = 1 -
alpha, method = method)
}
# Asymptotic (or Wald-test) CIs with continuity correction:
if (method == "asymptotic.cc") {
se = sqrt(p * (1 - p)/n)
CI = list(p = p, CI = c((p - z * se - 1/(2 * n)), (p + z * se + 1/(2 *
n))), n = n, level = 1 - alpha, method = method)
}
# Score test (or Wilson) interval:
if (method == "score") {
term1 = 2 * n * p + z^2
term2 = z * sqrt(z^2 + 4 * n * p * (1 - p))
term3 = 2 * (n + z^2)
CI = list(p = p, CI = c((term1 - term2)/term3, (term1 + term2)/term3),
n = n, level = 1 - alpha, method = method)
}
# Score test (or Wilson) interval with continuity correction:
if (method == "score.cc") {
term1 = 2 * n * p + z^2
if (p > 0) {
term2L = z * sqrt(z^2 - 2 - 1/n + 4 * p * (n * (1 - p) + 1))
}
if (p < 1) {
term2U = z * sqrt(z^2 + 2 - 1/n + 4 * p * (n * (1 - p) - 1))
}
term3 = 2 * (n + z^2)
if ((p > 0) & (p < 1)) {
CI = list(p = p, CI = c((term1 - 1 - term2L)/term3, (term1 + 1 +
term2U)/term3), n = n, level = 1 - alpha, method = method)
}
if (p == 0) {
CI = list(p = p, CI = c(0, CIU = (term1 + 1 + term2U)/term3), n = n,
level = 1 - alpha, method = method)
}
if (p == 1) {
CI = list(p = p, CI = c((term1 - 1 - term2L)/term3, 1), n = n, level = 1 -
alpha, method = method)
}
}
# Binomial ('exact' or Clopper-Pearson) interval:
if (method == "binomial") {
conf.int = binom.test(round(p * n), n, conf.level = 1 - alpha)$conf.int
CI = list(p = p, CI = c(conf.int[1], conf.int[2]), n = n, level = 1 -
alpha, method = method)
}
# Binomial mid-p quasi-exact interval:
if (method == "binomial.midp") {
x = round(p * n)
uplim = 1
lowlim = 0
if (x == 0)
uplim = 1 - alpha^(1/n)
if (x == n)
lowlim = alpha^(1/n)
if (x > 0 & x < n) {
pp = seq(1e-06, 0.999999, length = 1e+05)
a2 = 0.5 * pbinom(x - 1, n, pp) + 0.5 * pbinom(x, n, pp)
uplim = pp[max(which(a2 > (alpha/2)))]
lowlim = pp[min(which(a2 < (1 - alpha/2)))]
}
CI = list(p = p, CI = c(lowlim, uplim), n = n, level = 1 - alpha, method = method)
}
# Log-likelihood-ratio interval:
if (method == "likelihood") {
x = round(p * n)
k = -qchisq(1 - alpha, 1)/2
pp = seq(1e-06, 0.999999, length = 1e+05)
lik = dbinom(x, size = n, pp)
logLR = log(lik/max(lik))
conf.int = range(pp[logLR > k])
CI = list(p = p, CI = c(conf.int[1], conf.int[2]), n = n, level = 1 -
alpha, method = method)
}
# Jeffreys prior interval:
if (method == "Jeffreys") {
x = round(p * n)
conf.int = qbeta(c(alpha/2, 1 - alpha/2), x + 0.5, n - x + 0.5)
CI = list(p = p, CI = c(conf.int[1], conf.int[2]), n = n, level = 1 -
alpha, method = method)
}
# Agresti-Coull (adding z?/2 successes) interval (see:
# http://www.stat.ufl.edu/~aa/cda/R/one_sample/R1/index.html )
if (method == "Agresti-Coull") {
x = round(p * n)
tr = z^2
suc = tr/2
pp = (x + suc)/(n + tr)
se = sqrt(pp * (1 - pp)/(n + tr))
CI = list(p = p, CI = c((pp - z * se), (pp + z * se)), n = n, level = 1 -
alpha, method = method)
if (CI$CI[1] < 0)
CI$CI[1] = 0
if (CI$CI[2] > 1)
CI$CI[2] = 1
}
# Agresti-Coull (adding 2 successes and 2 failures) interval: (see:
# http://www.stat.ufl.edu/~aa/cda/R/one_sample/R1/index.html )
if (method == "Agresti.2_2") {
x = round(p * n)
pp = (x + 2)/(n + 4)
se = sqrt(pp * (1 - pp)/(n + 4))
CI = list(p = p, CI = c((pp - z * se), (pp + z * se)), n = n, level = 1 -
alpha, method = method)
if (CI$CI[1] < 0)
CI$CI[1] = 0
if (CI$CI[2] > 1)
CI$CI[2] = 1
}
# Logit interval:
if (method == "logit") {
lambda = log(p/(1 - p))
x = round(p * n)
V = n/(x * (n - x))
conf.int = (c(lambda - z * sqrt(V), lambda + z * sqrt(V)))
conf.int = exp(conf.int)/(1 + exp(conf.int))
CI = list(p = p, CI = c(conf.int[1], conf.int[2]), n = n, level = 1 -
alpha, method = method)
}
cat("p ? ", 100 * (1 - alpha), "%-CI = ", round(p, digits), " (", round(CI$CI[1],
digits), "; ", round(CI$CI[2], digits), ")\n", sep = "")
CI
}
prop.CI(.8, 10000)
prop.CI(.8, 10000, method = "asymptotic")
library(igraph)
get.adjacency(graph.formula(A+-B))
plot(graph.formula(A+-B))
summary(cars)
plot(cars)
library(igraph)
?plot.igraph
graph.adjacency
?graph.adjacency
s <- matrix(c(0, 2, 1, 0, 0, 0, 1, 2, 3), nrow = 3, ncol = 3)
s
graph.adjacency(s)
graph.adjacency(s, weighted = T)
g1 <- graph.adjacency(s, weighted = T)
g2 <- graph.adjacency(s)
plot.igraph(g1)
plot.igraph(g2)
g1 <- graph.adjacency(s, weighted = T, mode = "plus")
plot.igraph(g1)
g1 <- graph.adjacency(s, weighted = T, directed = F)
g1 <- graph.adjacency(s, weighted = T, mode = "undirected")
plot.igraph(g1)
g1 <- graph.adjacency(s, weighted = T, mode = "directed")
plot.igraph(g1)
s
g1
g1 <- graph.adjacency(s, weighted = T, mode = "upper")
plot.igraph(g1)
g1 <- graph.adjacency(s, weighted = T, mode = "directed")
plot.igraph(g1)
get.edgelist(g1)
plot.igraph(g1, arrow.mode = 2)
plot.igraph(g1, edge.arrow.mode = 2)
plot.igraph(g1, edge.arrow.mode = c(2,2,2,2,2))
plot.igraph(g1)
plot.igraph(g1, edge.curved = T)
g1 <- graph.adjacency(s, weighted = T, mode = "directed")
plot.igraph(g1, edge.curved = T)
plot.igraph(g1, edge.curved = T, edge.size = c(2,1,1,2,3))
plot.igraph(g1, edge.curved = T, edge.width = c(2,1,1,2,3))
get.edgelist(g1)
plot.igraph(g1, edge.curved = T, edge.width = c(2,1,1,2,3))
library(igraph)
library(NetIndices)
library(reshape2)
library(ggplot2)
library(devtools)
library(vegan)
url <- "https://raw.github.com/jjborrelli/Ecological-Networks/master/Food%20Webs/Rscripts/web_functions.R"
source_url(url)
### Import food web data  --------------------------------------------------
inputs <- get_webs("~/Dropbox/Food Web Database/Food_Web/Edgelist")
web.graphs <- inputs$graph.list
web.matrices <- inputs$adjacency.list
webnames <- inputs$webnames
setwd("~/Desktop/GitHub/Ecological-Networks/Food Webs")
z.stand <- read.csv("Tables/zscore_both.csv", row.names = 1)
z.stand <- apply(z.both, 2, FUN = function(x){x*abs(sum(x))})
z.stand <- apply(z.stand, 2, FUN = function(x){x*abs(sum(x))})
z.norm <- apply(z.stand, 2, FUN = function(x){(x * abs(sum(x)))/sqrt(sum(x^2))})
boxplot(z.norm[,names(sort(ms.mat))])
boxplot(z.norm)
z.norm
webnames
plot(z.norm[22,])
plot(z.stand[22,])
z.norm <- apply(z.stand, 2, FUN = function(x){(x * abs(sum(x)))/sqrt(sum(x^2))})
plot(z.norm[22,])
plot(z.norm[22,], type = "o")
getwd()
setwd("~/Downloads")
library(knitr)
setwd("~/Downloads")
pandoc("Week 5 quiz.md", format = "latex")
setwd("~/Desktop")
pandoc("Week 5 quiz.md", format = "latex")
pandoc("bioquiz.md", format = "latex")
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
require(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
tcp <- tc.plot + scale_x_continuous(breaks = 1:6)
require(RCurl)
require(igraph)
require(reshape2)
require(ggplot2)
require(grid)
require(devtools)
trophic.properties.URL <- getURL("https://raw.github.com/jjborrelli/Food-Chain-Length/master/Tables/NodeProperties.csv")
trophic.properties <- read.csv(text = trophic.properties.URL)
consumers <- which(round(trophic.properties$TL, 6) >= 2)
tc.plot<-qplot(trophic.properties$TL[consumers], binwidth = .8, geom = "histogram",
xlab = "Trophic Position", ylab = "Frequency")
tc.plot <- tc.plot + theme(axis.title.x = element_text(size = 20))
tc.plot <- tc.plot + theme(axis.title.y = element_text(size = 20))
tc.plot <- tc.plot + theme(axis.text.x = element_text(size = 15))
tc.plot <- tc.plot + theme(axis.text.y = element_text(size = 15))
tcp <- tc.plot + scale_x_continuous(breaks = 1:6)
set.seed(5)
eigenvalues<-list()
qss<-list()
for(i in 1:5){
eigenvalues[[i]]<-replicate(10000,analyze.eigen(sign.matrices[[i]]))
qss[[i]]<-sum(eigenvalues[[i]]<0)/10000
}
names(eigenvalues)<-c("2 sp","3 sp","4 sp","5 sp","6 sp")
names(qss)<-c("2 sp","3 sp","4 sp","5 sp", "6 sp")
qss
```
sign2<-matrix(c(-1,-1,1,0),nrow=2,ncol=2)
diag(sign2)<--1
sign3<-matrix(c(-1,-1,-1,1,0,-1,1,1,0),nrow=3,ncol=3)
diag(sign3)<--1
sign4<-matrix(nrow=4,ncol=4)
sign4[lower.tri(sign4)]<--1
sign4[upper.tri(sign4)]<-1
diag(sign4)<--1
sign5<-matrix(nrow=5,ncol=5)
sign5[lower.tri(sign5)]<--1
sign5[upper.tri(sign5)]<-1
diag(sign5)<--1
sign6<-matrix(nrow=6,ncol=6)
sign6[lower.tri(sign6)]<--1
sign6[upper.tri(sign6)]<-1
diag(sign6)<--1
sign.matrices<-list(sign2,sign3,sign4,sign5,sign6)
names(sign.matrices)<-c("2 sp","3 sp","4 sp","5 sp","6 sp")
analyze.eigen<-function(m){
for(i in 1:nrow(m)){
for (j in 1:nrow(m)){
ifelse(m[i,j]==1,m[i,j]<-runif(1,0,10),NA)
ifelse(m[i,j]==-1,m[i,j]<-runif(1,-1,0),NA)
}
}
for(i in 1:nrow(m)){
if(m[i,i]<0){m[i,i]<--1}
}
ev<-max(Re(eigen(m)$values))
return(ev)
}
set.seed(5)
eigenvalues<-list()
qss<-list()
for(i in 1:5){
eigenvalues[[i]]<-replicate(10000,analyze.eigen(sign.matrices[[i]]))
qss[[i]]<-sum(eigenvalues[[i]]<0)/10000
}
names(eigenvalues)<-c("2 sp","3 sp","4 sp","5 sp","6 sp")
names(qss)<-c("2 sp","3 sp","4 sp","5 sp", "6 sp")
qss
set.seed(10)
analyze.eigen.sensitivity1<-function(m){
for(i in 1:nrow(m)){
for (j in 1:nrow(m)){
ifelse(m[i,j]==1,m[i,j]<-runif(1,0,10),NA)
ifelse(m[i,j]==-1,m[i,j]<-runif(1,-5,0),NA)  #note the difference in distribution here
}
}
for(i in 1:nrow(m)){
if(m[i,i]<0){m[i,i]<--1}
}
ev<-max(Re(eigen(m)$values))
return(ev)
}
eigenvalues.sensitivity1<-list()
qss.sensitivity1<-list()
for(i in 1:5){
eigenvalues.sensitivity1[[i]]<-replicate(10000,analyze.eigen.sensitivity1(sign.matrices[[i]]))
qss.sensitivity1[[i]]<-sum(eigenvalues.sensitivity1[[i]]<0)/10000
}
names(eigenvalues.sensitivity1)<-c("2 sp","3 sp","4 sp","5 sp","6 sp")
names(qss.sensitivity1)<-c("2 sp","3 sp","4 sp","5 sp", "6 sp")
qss.sensitivity1
set.seed(15)
analyze.eigen.sensitivity2<-function(m){
for(i in 1:nrow(m)){
for (j in 1:nrow(m)){
ifelse(m[i,j]==1,m[i,j]<-runif(1,0,10),NA)
ifelse(m[i,j]==-1,m[i,j]<-runif(1,-0.1,0),NA)  #note the difference in distribution here
}
}
for(i in 1:nrow(m)){
if(m[i,i]<0){m[i,i]<--1}
}
ev<-max(Re(eigen(m)$values))
return(ev)
}
eigenvalues.sensitivity2<-list()
qss.sensitivity2<-list()
for(i in 1:5){
eigenvalues.sensitivity2[[i]]<-replicate(10000,analyze.eigen.sensitivity2(sign.matrices[[i]]))
qss.sensitivity2[[i]]<-sum(eigenvalues.sensitivity2[[i]]<0)/10000
}
names(eigenvalues.sensitivity2)<-c("2 sp","3 sp","4 sp","5 sp","6 sp")
names(qss.sensitivity2)<-c("2 sp","3 sp","4 sp","5 sp", "6 sp")
qss.sensitivity2
set.seed(20)
analyze.eigen.sensitivity3<-function(m){
for(i in 1:nrow(m)){
for (j in 1:nrow(m)){
ifelse(m[i,j]==1,m[i,j]<-runif(1,0,10),NA)
ifelse(m[i,j]==-1,m[i,j]<-runif(1,-0.01,0),NA)  #note the difference in distribution here
}
}
for(i in 1:nrow(m)){
if(m[i,i]<0){m[i,i]<--1}
}
ev<-max(Re(eigen(m)$values))
return(ev)
}
eigenvalues.sensitivity3<-list()
qss.sensitivity3<-list()
for(i in 1:5){
eigenvalues.sensitivity3[[i]]<-replicate(10000,analyze.eigen.sensitivity3(sign.matrices[[i]]))
qss.sensitivity3[[i]]<-sum(eigenvalues.sensitivity3[[i]]<0)/10000
}
names(eigenvalues.sensitivity3)<-c("2 sp","3 sp","4 sp","5 sp","6 sp")
names(qss.sensitivity3)<-c("2 sp","3 sp","4 sp","5 sp", "6 sp")
qss.sensitivity3
qtab <- list(qss, qss.sensitivity2, qss.sensitivity3, qss.sensitivity1)
names(qtab) <- c("U (-1.0, 0)", "U (-0.1, 0)", "U (-0.01, 0)", "U (-5.0, 0)")
qss.data <- melt(qtab, id = c("2 sp", "3 sp", "4 sp", "5 sp", "6 sp"))
colnames(qss.data) <- c("QSS", "Levels", "Distribution")
qss.data$Levels <- c(2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6)
qss.data$Distribution2 <- factor(qss.data$Distribution,
levels = (c("U (-1.0, 0)", "U (-0.1, 0)", "U (-0.01, 0)", "U (-5.0, 0)")))
qss.plot <- qplot(Levels, QSS, data = qss.data, xlab = "Number of Trophic Levels", margin = T)
qss.plot <- qss.plot + geom_point(aes(shape = qss.data$Distribution2), size = 4)
qss.plot <- qss.plot + geom_line(aes(linetype = qss.data$Distribution2))
qss.plot <- qss.plot + theme(legend.title = element_blank())
qss.plot <- qss.plot + theme(legend.key.size = unit(2, "cm"), legend.text = element_text(size = 20))
qss.plot <- qss.plot + theme(axis.title.x = element_text(size=25))
qss.plot <- qss.plot + theme(axis.title.y = element_text(size=25))
qss.plot <- qss.plot + theme(axis.text.x = element_text(size=18))
qss.plot <- qss.plot + theme(axis.text.y = element_text(size=18))
multiplot(tcp, qss.plot, cols = 2)
getwd()
ggsave("fig1.svg")
ggsave("fig1.svg", height = 10, width = 20, dpi = 600)
boxplot(z.norm)
system.time(
permutes <- web_permutation(web.matrices, fixedmar = "both", times = 1000)
)
permean.both<- sapply(permutes, FUN = function(x){apply(x[,2:14], 2, mean)})
persd.both<- sapply(permutes, FUN = function(x){apply(x[,2:14], 2, sd)})
z.both <- (sub.counts - t(permean.both)) / t(persd.both)
z.both[is.nan(as.matrix(z.both))] <- 0
z.norm <- apply(z.stand, 2, FUN = function(x){(x * abs(sum(x)))/sqrt(sum(x^2))})
write.csv(z.norm, file = "Tables/zscore_both.csv")
z.norm <- read.csv("Tables/zscore_both.csv", row.names = 1)
boxplot(z.norm)
motif.df <- read.table("Tables/motifCOUNTS.csv", header = T, sep = ",", row.names = 1)
sub.counts <- motif.df[,2:14]
setwd("~/Desktop/GitHub/Ecological-Networks/Food Webs")
list.files()
motif.df <- read.table("Tables/motifCOUNTS.csv", header = T, sep = ",", row.names = 1)
sub.counts <- motif.df[,2:14]
z.both <- (sub.counts - t(permean.both)) / t(persd.both)
z.both[is.nan(as.matrix(z.both))] <- 0
z.norm <- apply(z.stand, 2, FUN = function(x){(x * abs(sum(x)))/sqrt(sum(x^2))})
write.csv(z.norm, file = "Tables/zscore_both.csv")
boxplot(z.norm)
abline(h = 0)
